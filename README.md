# Ex-01_DS_Data_Cleansing
Name:Gokulan.R

Reg No:212224230076
## AIM
To read the given data and perform data cleaning and save the cleaned data to a file. 

# Explanation
Data cleaning is the process of preparing data for analysis by removing or modifying data that is incorrect ,incompleted , irrelevant , duplicated or improperly formatted. 
Data cleaning is not simply about erasing data ,but rather finding a way to maximize datasets accuracy without necessarily deleting the information. 

# ALGORITHM
### STEP 1
Read the given Data
### STEP 2
Get the information about the data
### STEP 3
Remove the null values from the data
### STEP 4
Save the Clean data to the file

# CODE and OUTPUT
![Screenshot 2025-03-14 113355](https://github.com/user-attachments/assets/a2578f6c-5743-42da-af00-6cbd1564ea7e)
![Screenshot 2025-03-14 113412](https://github.com/user-attachments/assets/bf81a471-79be-4abe-bfa2-410df76e0ca2)
![Uploading Screenshot 2025-03-14 113412.pngâ€¦]()
![Screenshot 2025-03-14 113430](https://github.com/user-attachments/assets/ecb435b0-f8cd-4a69-84a7-5b1028d6d365)
![Screenshot 2025-03-14 113445](https://github.com/user-attachments/assets/e1962bf9-8c77-413c-915f-823430e657f1)
![Screenshot 2025-03-14 113507](https://github.com/user-attachments/assets/5cb4ecdc-77ef-4785-91bb-642f956baf42)
![Screenshot 2025-03-14 113521](https://github.com/user-attachments/assets/80e61722-ecec-4e5c-b834-08e9086bd9fb)
![Screenshot 2025-03-14 113531](https://github.com/user-attachments/assets/234a9472-a598-4d3c-bc58-b96220f84b64)
![Screenshot 2025-03-14 113543](https://github.com/user-attachments/assets/f41d1c11-b7ce-4b9c-ad45-a579a5f07ec5)
![Screenshot 2025-03-14 113543](https://github.com/user-attachments/assets/f41d1c11-b7ce-4b9c-ad45-a579a5f07ec5)
![Screenshot 2025-03-14 113601](https://github.com/user-attachments/assets/3e591d42-fd5d-4d77-b0ed-ba63db1e4e33)
![Screenshot 2025-03-14 113615](https://github.com/user-attachments/assets/3b301032-fd97-4e82-b4b0-4503e1e8918f)

![Screenshot 2025-03-14 113630](https://github.com/user-attachments/assets/c9bdac07-b680-4130-bb4a-8e97790507c3)

![Screenshot 2025-03-14 113636](https://github.com/user-attachments/assets/6cd7db8e-051d-4de6-b0df-286183cefda4)

![Screenshot 2025-03-14 113646](https://github.com/user-attachments/assets/1902c1c1-318c-49f1-a697-bd3a1234fdad)

![Screenshot 2025-03-14 113702](https://github.com/user-attachments/assets/6bde9672-9bf9-4862-b713-b4b436885b1b)

![Screenshot 2025-03-14 113719](https://github.com/user-attachments/assets/fc19b412-9244-4f54-91ca-e90fbf2392c1)

![Screenshot 2025-03-14 113728](https://github.com/user-attachments/assets/76c49764-6fb7-4fb2-a449-b233fe000437)

![Screenshot 2025-03-14 113735](https://github.com/user-attachments/assets/affefb20-344b-49d7-8a88-852aefe91fdd)

![Screenshot 2025-03-14 113750](https://github.com/user-attachments/assets/e0b9c104-6087-4ed6-9714-ccda08444f5e)

![Screenshot 2025-03-14 113757](https://github.com/user-attachments/assets/dfa0edc6-784f-44b4-a68f-4edb7b4fb9b0)

![Screenshot 2025-03-14 113805](https://github.com/user-attachments/assets/129d7440-fcc1-4eb4-bdfc-ecde6066732b)

# Result
Thus we have cleaned the data and removed the outliers by detection using IQR and Z-score method.
